{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install stanfordnlp\n",
    "%pip install senticnet\n",
    "%pip install sentistrength\n",
    "%pip install nltk\n",
    "%pip install spacy\n",
    "%pip install sklearn\n",
    "%pip install numpy\n",
    "\n",
    "# run this in the terminal\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import requests\n",
    "from senticnet.senticnet import SenticNet\n",
    "from sentistrength import PySentiStr\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "# stanfordNLP = StanfordCoreNLP(\"http://localhost\", port=8000, timeout=30000)\n",
    "spacyNLP = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the zip file from the link https://drive.google.com/file/d/1yvCpB2URy0iFjQPn3RmidNOryTlo6vHG/view?usp=share_link\n",
    "# extract the zip file and place the folder in the same directory as this file then cd into the folder\n",
    "# run the following command in the terminal to start the server\n",
    "# java -mx4g -cp \"*\" edu.stanford.stanfordNLP.pipeline.StanfordCoreNLPServer -port {8000 or any port} -timeout 30000\n",
    "# can speed it up by replace 4g with 8g (it represents the ram being used in gigs)\n",
    "def lemmatize(text):\n",
    "    # perform lemmatization\n",
    "    lemmas = []\n",
    "    output = stanfordNLP.annotate(text, properties={'annotators': 'tokenize,lemma', 'outputFormat': 'json'})\n",
    "    output_dict = json.loads(output)\n",
    "    tokens = output_dict['sentences'][0]['tokens']\n",
    "    for token in tokens:\n",
    "        lemmas.append(token['lemma'])\n",
    "   \n",
    "    return lemmas  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the given JSON file into actual JSON format for easier readbility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFile = open(\"Sarcasm_Headlines.json\", \"w\")\n",
    "writeFile.write(\"{ \\\"headlines\\\": [\")\n",
    "with open(\"Sarcasm_Headlines_Dataset.json\") as readFile:\n",
    "  for item in readFile:\n",
    "    writeFile.write(item + \",\")\n",
    "# removed the final comma manually\n",
    "writeFile.write(\"]}\")\n",
    "readFile.close()\n",
    "writeFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Stage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset and removing all article links as our goal is to analyze the headlines for sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open(\"Sarcasm_Headlines.json\"))\n",
    "df = pd.DataFrame(dataset[\"headlines\"])\n",
    "df.drop([\"article_link\"], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizeDataset():\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['headline']\n",
    "        row['headline'] = lemmatize(sentence)\n",
    "\n",
    "lemmatizeDataset()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writing to a csv file to avoid having to perform pre-processing again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lemmatized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 => Concept Level and Common Sense Knowledge\n",
    "### ConceptNet\n",
    "ConceptNet is a semantic network consisting of common-sense knowledge and concepts, represented<br> in the form of nodes (words or\n",
    "short phrases) and labeled edges (relationships) between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the API endpoint and parameters\n",
    "endpoint = 'http://api.conceptnet.io/c/en/'\n",
    "params = {\n",
    "    'filter': 'core',\n",
    "    'limit': 1000\n",
    "}\n",
    "def conceptNet(sentence):\n",
    "    # send a GET request to the API endpoint\n",
    "    response = requests.get(endpoint + sentence, params=params)\n",
    "\n",
    "    # parse the JSON response\n",
    "    data = json.loads(response.text)\n",
    "    edges = data['edges']\n",
    "    edges.sort(key=lambda x: x['weight'], reverse=True)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 => Sentiment Score\n",
    "### SentiStrength\n",
    "SentiStrength is a sentiment lexicon that uses linguistic information and rules to detect<br>\n",
    "sentiment strength in English text. SentiStrength provides positive and negative sentiment<br>\n",
    "scores for each word. Both scores are integers from 1 to 5, where 1 signifies weak sentiment<br>\n",
    "and 5 signifies strong sentiment.\n",
    "<br>\n",
    "polarity = positiveSentiment - negativeSentiment\n",
    "\n",
    "### SenticNet\n",
    "SenticNet is a resource for opinion mining that aims to create a collection of commonly<br> \n",
    "used common-sense concepts  with positive and negative sentiment scores. The sentiment <br>\n",
    "score for each word is scaled from -1 to 1, where -1 signifies strongly negative sentiment,<br>\n",
    "0 signifies neutral sentiment and 1 signifies strong positive sentiment.\n",
    "<br> sentiment = score * 5 (in-order to keep it with sentiStrength)\n",
    "\n",
    "### Rules of w_score (sentiment score) selection:\n",
    "- if word belongs to SentiStrength || SenticNet => pick the score whichever exists\n",
    "- if word belongs to SentiStrength && SenticNet => avg score of the lexicons\n",
    "- else get the concepts from concept net to expand the meaning => select top 5 ranked and calculate the avg sentiment score\n",
    "\n",
    "### Final Calculation\n",
    "sum_pos_score = sum of all positive sentiment scores<br>\n",
    "sum_neg_score = sum of all negative sentiment scores<br>\n",
    "if sum_pos_score && sum_neg_score > 0, there is a contradiction in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = SenticNet()\n",
    "def senticNetScore(word):\n",
    "    try:\n",
    "        polarityValue = sn.polarity_value(word)\n",
    "        return float(polarityValue) * 5\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = PySentiStr()\n",
    "# got the jar file and data folder from the author (also reverse engineered the pysenti package to extract the jar file)\n",
    "senti.setSentiStrengthPath('D:/Sarcasm_Detection-Feature_Selection/SentiStrengthCom.jar')\n",
    "senti.setSentiStrengthLanguageFolderPath('D:/Sarcasm_Detection-Feature_Selection/SentStrength_Data')\n",
    "def sentiStrengthScore(word):\n",
    "    result = senti.getSentiment(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wScore(word):\n",
    "    senticNet = senticNetScore(word)\n",
    "    sentiStrength = sentiStrengthScore(word)[0]\n",
    "    if senticNet == None and sentiStrength == None:\n",
    "        expansion = conceptNet(word)\n",
    "        if len(expansion) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            score = 0\n",
    "            expansion = expansion[:5]\n",
    "            for edge in expansion:\n",
    "                score += wScore(edge['end']['label'])\n",
    "            return score / 5\n",
    "    elif senticNet == None:\n",
    "        return sentiStrength\n",
    "    elif sentiStrength == None:\n",
    "        return senticNet\n",
    "    else:\n",
    "        return (senticNet + sentiStrength) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positiveScore(results):\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        if result > 0:\n",
    "            score += result\n",
    "    return score\n",
    "def negativeScore(results):\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        if result < 0:\n",
    "            score += result\n",
    "    return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 => Sentence Coherence\n",
    "Checking the coreference between subjects or objects of a sentence\n",
    "<br> for two subjects w1 and w2, sentence is coherent if\n",
    "- if w1 is antecedent of w2\n",
    "- if w1 and w2 are identical pronouns\n",
    "- if w1 and w2 are identical subjects\n",
    "- w2 starts with the word \"the\" (Definite Noun Phrase)\n",
    "- w2 starts with \"this\", \"that\", \"these\", \"those\" (Demonstrative Noun Phrases)\n",
    "- if w1 and w2 are proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubject(sentence):\n",
    "    doc = spacyNLP(sentence)\n",
    "    subject = None\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"nsubj\":\n",
    "            subject = token.text\n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasAntecedents(text):\n",
    "    doc = spacyNLP(text)\n",
    "    antecedents = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "            for mention in doc.ents:\n",
    "                if mention.start <= token.i < mention.end:\n",
    "                    antecedents.append(mention.text)\n",
    "    return True if len(antecedents) > 0 else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronounLemmatizer = WordNetLemmatizer()\n",
    "def identicalPronouns(w1, w2):\n",
    "    lemma1 = pronounLemmatizer.lemmatize(w1, 'n')\n",
    "    lemma2 = pronounLemmatizer.lemmatize(w2, 'n')\n",
    "    if lemma1 == lemma2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identicalSubjects(w1,w2):\n",
    "    cleanedSubject1 = re.sub(r'[^a-zA-Z]', '', w1)\n",
    "    cleanedSubject2 = re.sub(r'[^a-zA-Z]', '', w2)\n",
    "    if cleanedSubject1 == cleanedSubject2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definiteNounPhraseFeature(text,w2):\n",
    "    doc = nltk.word_tokenize(text)\n",
    "    for i in range(len(doc)):\n",
    "        if i-1 >= 0 and doc[i] == w2:\n",
    "            if doc[i-1] == 'the':\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrativeNounPhraseFeature(text,w2):\n",
    "    doc = nltk.word_tokenize(text)\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i] == w2:\n",
    "            if i-1 >= 0 and doc[i-1] == 'this' or doc[i-1] == 'that' or doc[i-1] == 'these' or doc[i-1] == 'those':\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def properNameFeature(w1,w2):\n",
    "    taggedWords = nltk.pos_tag([w1,w2])\n",
    "    proper = False\n",
    "    for word, tag in taggedWords:\n",
    "        if tag in ['NNP', 'NNPS']:\n",
    "            proper = True\n",
    "        else:\n",
    "            proper = False\n",
    "            break\n",
    "    return proper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 => Creation of Feature Vector\n",
    "\n",
    "### N-Grams Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headlines = df.drop('is_sarcastic',axis='columns')\n",
    "# sentences = df['headline']\n",
    "def remove_symbols(line):\n",
    "    return ''.join(ch for ch in line if ch.isalnum() or ch == \" \")\n",
    "\n",
    "# def createNgrams(sentence):\n",
    "#     ngrams = []\n",
    "#     sentence = remove_symbols(sentence)\n",
    "#     tokens = nltk.word_tokenize(sentence)\n",
    "#     bigrams = list(nltk.bigrams(tokens))\n",
    "#     trigrams = list(nltk.trigrams(tokens))\n",
    "#     return tokens, bigrams, trigrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 74.9 GiB for an array with shape (26709, 376536) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m vectorizer \u001b[39m=\u001b[39m CountVectorizer(ngram_range\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m     34\u001b[0m res \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform(sentences)\n\u001b[1;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(res\u001b[39m.\u001b[39;49mtoarray())\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 74.9 GiB for an array with shape (26709, 376536) and data type int64"
     ]
    }
   ],
   "source": [
    "# def createFeatureSpaces():\n",
    "#     uni = []\n",
    "#     bi = []\n",
    "#     tri = []\n",
    "#     for sentence in sentences:\n",
    "#         unigram, bigrams, trigrams = createNgrams(sentence)\n",
    "#         for word in unigram:\n",
    "#             uni.append(word)\n",
    "#         for word in bigrams:\n",
    "#             bi.append(\"{} {}\".format(word[0], word[1]))\n",
    "#         for word in trigrams:\n",
    "#             tri.append(\"{} {} {}\".format(word[0], word[1], word[2]))\n",
    "#     uni = list(set(uni))\n",
    "#     bi = list(set(bi))\n",
    "#     tri = list(set(tri))\n",
    "#     print(\"Length of unigrams: \",len(uni))\n",
    "#     print(\"Length of bigrams: \",len(bi))\n",
    "#     print(\"Length of trigrams: \",len(tri))\n",
    "#     data = {col: np.zeros(len(df)) for col in uni}\n",
    "#     print(\"Created Unigrams\")\n",
    "#     unigramSpace = pd.DataFrame(data)\n",
    "#     print(\"Created Unigrams\")\n",
    "#     data = {col: np.zeros(len(df)) for col in bi}\n",
    "#     print(\"Created Bigrams\")\n",
    "#     bigramSpace = pd.DataFrame(data)\n",
    "#     print(\"Created Bigrams\")\n",
    "#     data = {col: np.zeros(len(df)) for col in tri}\n",
    "#     print(\"Created Bigrams\")\n",
    "#     trigramSpace = pd.DataFrame(data)\n",
    "#     print(\"Created Trigrams\")\n",
    "#     return unigramSpace, bigramSpace, trigramSpace\n",
    "# # unigramSpace, bigramSpace, trigramSpace = createFeatureSpaces()\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "# res = vectorizer.fit_transform(sentences)\n",
    "# print(res.toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contradiction Feature: <br>\n",
    "<emsp>We use two binary features Contra and Contra_Coher<br>\n",
    "<emsp>Contra if headline has one sentence and contradiction in sentiment score occur\n",
    "<br>\n",
    "<emsp>Contra_Coher if headline has more than one sentence, contradiction of polarity and the headline is judged coherent<br>\n",
    "- Sentiment Feature <br>\n",
    "<emsp>Calculates the +ve and -ve score of the headline and then classify it as low/med/high\n",
    "- Punctuation <br>\n",
    "<emsp>We use 7 indicators<br><br>\n",
    "    <emsp><emsp>1. Number of emoticons <br>\n",
    "    <emsp><emsp>2. Number of repetitive sequence of punctuations<br>\n",
    "    <emsp><emsp>3. Number of repetitive sequence of characters<br>\n",
    "    <emsp><emsp>4. Number of capitalized word<br>\n",
    "    <emsp><emsp>5. Number of slang and booster words<br>\n",
    "    <emsp><emsp>6. Number of exclamation marks<br>\n",
    "    <emsp><emsp>7. Number of idioms<br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CONTRA\"] = np.zeros(len(df))\n",
    "df[\"CONTRA_PLUS_COHER\"] = np.zeros(len(df))\n",
    "df[\"pos_low\"] = np.zeros(len(df))\n",
    "df[\"pos_med\"] = np.zeros(len(df))\n",
    "df[\"pos_high\"] = np.zeros(len(df))\n",
    "df[\"neg_low\"] = np.zeros(len(df))\n",
    "df[\"neg_med\"] = np.zeros(len(df))\n",
    "df[\"neg_high\"] = np.zeros(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  former versace store clerk sues over secret black code for minority shoppers\n",
      "positiveScore:  2.1725000000000003\n",
      "negativeScore:  -1.6\n",
      "CONTRA\n",
      "Sentence:  the roseanne revival catches up to our thorny political mood for better and worse\n",
      "positiveScore:  7.704999999999999\n",
      "negativeScore:  -8.399999999999999\n",
      "CONTRA\n",
      "Sentence:  mom starting to fear sons web series closest thing she will have to grandchild\n",
      "positiveScore:  4.290000000000001\n",
      "negativeScore:  -3.1500000000000004\n",
      "CONTRA\n",
      "Sentence:  boehner just wants wife to listen not come up with alternative debtreduction ideas\n",
      "positiveScore:  4.2425\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  jk rowling wishes snape happy birthday in the most magical way\n",
      "positiveScore:  9.002500000000001\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  advancing the worlds women\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  the fascinating case for eating labgrown meat\n",
      "positiveScore:  5.905\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  this ceo will send your kids to school if you work for his company\n",
      "positiveScore:  4.5\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  top snake handler leaves sinking huckabee campaign\n",
      "positiveScore:  3.075\n",
      "negativeScore:  -0.55\n",
      "CONTRA\n",
      "Sentence:  fridays morning email inside trumps presser for the ages\n",
      "positiveScore:  0\n",
      "negativeScore:  -1.6\n",
      "CONTRA\n",
      "Sentence:  airline passengers tackle man who rushes cockpit in bomb threat\n",
      "positiveScore:  3.8425\n",
      "negativeScore:  -3.3\n",
      "CONTRA\n",
      "Sentence:  facebook reportedly working on healthcare features and apps\n",
      "positiveScore:  2.875\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  north korea praises trump and urges us voters to reject dull hillary\n",
      "positiveScore:  2\n",
      "negativeScore:  -3.1750000000000003\n",
      "CONTRA\n",
      "Sentence:  actually cnns jeffrey lord has been indefensible for a while\n",
      "positiveScore:  2.25\n",
      "negativeScore:  -0.475\n",
      "CONTRA\n",
      "Sentence:  barcelona holds huge protest in support of refugees\n",
      "positiveScore:  2.9625\n",
      "negativeScore:  -3.925\n",
      "CONTRA\n",
      "Sentence:  nuclear bomb detonates during rehearsal for spiderman musical\n",
      "positiveScore:  1.75\n",
      "negativeScore:  -0.2\n",
      "CONTRA\n",
      "Sentence:  cosby lawyer asks why accusers didnt come forward to be smeared by legal team years ago\n",
      "positiveScore:  0.7224999999999999\n",
      "negativeScore:  -3.1\n",
      "CONTRA\n",
      "Sentence:  stock analysts confused frightened by boar market\n",
      "positiveScore:  0\n",
      "negativeScore:  -4.475\n",
      "CONTRA\n",
      "Sentence:  bloombergs program to build better cities just got bigger\n",
      "positiveScore:  3.2375\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  craig hicks indicted\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  courtroom sketch artist has clear manga influences\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  trump assures nation that decision for syrian airstrikes came after carefully considering all his passing whims\n",
      "positiveScore:  0.2225\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  qatar deporting dutch woman who reported she was drugged and raped\n",
      "positiveScore:  0\n",
      "negativeScore:  -4.6\n",
      "CONTRA\n",
      "Sentence:  this is why you shouldnt go to the circus\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  ted cruz hits the panic button we could lose both houses of congress\n",
      "positiveScore:  0\n",
      "negativeScore:  -4.15\n",
      "CONTRA\n",
      "Sentence:  why writers must plan to be surprised\n",
      "positiveScore:  3.35\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  obama visits arlington national cemetery to honor veterans\n",
      "positiveScore:  1.9900000000000002\n",
      "negativeScore:  -2.2\n",
      "CONTRA\n",
      "Sentence:  excon back behind bar\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  after careful consideration bush recommends oil drilling\n",
      "positiveScore:  4.359999999999999\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  remembrance is the beginning of the task\n",
      "positiveScore:  0.32\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  allies islamist motive for killing nemtsov is nonsense\n",
      "positiveScore:  0.21749999999999997\n",
      "negativeScore:  -2.8\n",
      "CONTRA\n",
      "Sentence:  gillian jacobs on what its like to kiss adam brody\n",
      "positiveScore:  2.115\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  uber vows to repay nyc drivers tens of millions after tax snafu\n",
      "positiveScore:  0\n",
      "negativeScore:  -2.4\n",
      "CONTRA\n",
      "Sentence:  apple may have poached electric motorcycle company to death\n",
      "positiveScore:  2.1975\n",
      "negativeScore:  -3.0749999999999997\n",
      "CONTRA\n",
      "Sentence:  drugresistant bacteria often lurk in childrens dogs sandboxes\n",
      "positiveScore:  0.915\n",
      "negativeScore:  -1.875\n",
      "CONTRA\n",
      "Sentence:  if you see a muslim at the airport\n",
      "positiveScore:  0.295\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  giant altoid heading toward earth\n",
      "positiveScore:  2.25\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  moana sails straight to the top of the box office with massive 811 million opening\n",
      "positiveScore:  4.5\n",
      "negativeScore:  -2.25\n",
      "CONTRA\n",
      "Sentence:  selig counted money while baseball lost the next generation of fans\n",
      "positiveScore:  2.4825000000000004\n",
      "negativeScore:  -2.05\n",
      "CONTRA\n",
      "Sentence:  robin williams inflicted on holiday moviegoers for eighth straight year\n",
      "positiveScore:  1.1\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  devin nunes vows to never reveal source of surveillance claims\n",
      "positiveScore:  2.25\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  scott used to stop breathing nearly 40 times an hour this device changed his life\n",
      "positiveScore:  0.2775\n",
      "negativeScore:  -2.0250000000000004\n",
      "CONTRA\n",
      "Sentence:  rescuers heroically help beached garbage back into ocean\n",
      "positiveScore:  7.175\n",
      "negativeScore:  -3.925\n",
      "CONTRA\n",
      "Sentence:  medics drop soccer player from stretcher hes ticked\n",
      "positiveScore:  0\n",
      "negativeScore:  -0.925\n",
      "CONTRA\n",
      "Sentence:  give the gift of play this holiday season\n",
      "positiveScore:  1.87\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  christian bale visits sikh temple victims\n",
      "positiveScore:  0\n",
      "negativeScore:  -2\n",
      "CONTRA\n",
      "Sentence:  spicer denies that ending maternity care guarantee would mean women pay more for health care\n",
      "positiveScore:  3.83\n",
      "negativeScore:  -0.42500000000000004\n",
      "CONTRA\n",
      "Sentence:  right to live life in complete stunned horror added to constitution\n",
      "positiveScore:  2.16\n",
      "negativeScore:  -3\n",
      "CONTRA\n",
      "Sentence:  nasa now almost positive mars is rocky\n",
      "positiveScore:  4.115\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  monster undeterred by nightlight\n",
      "positiveScore:  0\n",
      "negativeScore:  -1.125\n",
      "CONTRA\n",
      "Sentence:  diy sports equipment closet\n",
      "positiveScore:  0.0975\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  1 dead 3 injured in shooting at ti concert in nyc\n",
      "positiveScore:  2.0075000000000003\n",
      "negativeScore:  -6.9\n",
      "CONTRA\n",
      "Sentence:  longtime teacher retires without changing a single students life\n",
      "positiveScore:  0.6675\n",
      "negativeScore:  -1.4\n",
      "CONTRA\n",
      "Sentence:  donald trump heading for a series of wins in the northeast polls say\n",
      "positiveScore:  2.25\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  donald trump wouldnt have had the ready cash to selffinance entire campaign  analysis\n",
      "positiveScore:  4.784999999999999\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  new star wars film once again disappoints diehard nien nunb fans\n",
      "positiveScore:  4.3025\n",
      "negativeScore:  -4\n",
      "CONTRA\n",
      "Sentence:  bats shooed out of nations waterslide tunnels in preparation for summer\n",
      "positiveScore:  5.29\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  mobile news crew reports on own van breaking down\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  un rights chief calls humanitarian situation in syria an outrage\n",
      "positiveScore:  1.945\n",
      "negativeScore:  -1.0\n",
      "CONTRA\n",
      "Sentence:  how to track santa claus flight around the world this christmas eve\n",
      "positiveScore:  2.5875000000000004\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  obama has colorado appraised\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  trouble again in tvs africa\n",
      "positiveScore:  0\n",
      "negativeScore:  -2.5250000000000004\n",
      "CONTRA\n",
      "Sentence:  brita unveils new inthroat water filters\n",
      "positiveScore:  2.66\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  report john grisham slowly but surely climbing list of greatest living american authors\n",
      "positiveScore:  7.175000000000001\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  ghost cant make a simple cup of coffee without everyone freaking out\n",
      "positiveScore:  2.5599999999999996\n",
      "negativeScore:  -5.0\n",
      "CONTRA\n",
      "Sentence:  tupperware will never truly recover from red curry leftovers\n",
      "positiveScore:  4.1925\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  one of the planets most powerful forces for change an adolescent girl\n",
      "positiveScore:  5.1225000000000005\n",
      "negativeScore:  -1.6\n",
      "CONTRA\n",
      "Sentence:  how does draymond green take his game to the next level by tuning in to the wnba\n",
      "positiveScore:  0.6725000000000001\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  area woman said sorry 118 times yesterday\n",
      "positiveScore:  0\n",
      "negativeScore:  -1.25\n",
      "CONTRA\n",
      "Sentence:  ryan lochte apologizes for behavior in rio\n",
      "positiveScore:  0\n",
      "negativeScore:  -1.975\n",
      "CONTRA\n",
      "Sentence:  north dakota not heard from in 48 hours\n",
      "positiveScore:  0\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  4 lessons prison taught me about power and control\n",
      "positiveScore:  4.5625\n",
      "negativeScore:  -2.5749999999999997\n",
      "CONTRA\n",
      "Sentence:  sick fucks line up to gape at dead body\n",
      "positiveScore:  0\n",
      "negativeScore:  -6.825\n",
      "CONTRA\n",
      "Sentence:  what is americas first muslim fraternity really like\n",
      "positiveScore:  1\n",
      "negativeScore:  -2.0749999999999997\n",
      "CONTRA\n",
      "Sentence:  the vicious knot of syria the untangling process contains solutions in our time\n",
      "positiveScore:  0.8175\n",
      "negativeScore:  -2.325\n",
      "CONTRA\n",
      "Sentence:  this congressman thinks we can fix the economy by drinking beer\n",
      "positiveScore:  1.1\n",
      "negativeScore:  -5.7250000000000005\n",
      "CONTRA\n",
      "Sentence:  breast implants found to cause problems in laboratory mice\n",
      "positiveScore:  4.045\n",
      "negativeScore:  -2.5250000000000004\n",
      "CONTRA\n",
      "Sentence:  trump orders strikes on syria in retaliation for chemical attack\n",
      "positiveScore:  0\n",
      "negativeScore:  -4.475\n",
      "CONTRA\n",
      "Sentence:  ceos funeral a networking dream\n",
      "positiveScore:  2.25\n",
      "negativeScore:  -2.2\n",
      "CONTRA\n",
      "Sentence:  yearround schooling how it would help minority students\n",
      "positiveScore:  2.25\n",
      "negativeScore:  -1.6\n",
      "CONTRA\n",
      "Sentence:  90 zen teachers pledge to change culture that fosters abuse\n",
      "positiveScore:  1.6225000000000003\n",
      "negativeScore:  -2.6\n",
      "CONTRA\n",
      "Sentence:  nypd weighs allowing chokeholds following eric garner death\n",
      "positiveScore:  2.42\n",
      "negativeScore:  -6.074999999999999\n",
      "CONTRA\n",
      "Sentence:  sonny bono foundation prevents atrisk youths from skiing into trees\n",
      "positiveScore:  4.0725\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  pope francis reminds the world that caring for the earth is everyones responsibility\n",
      "positiveScore:  4.8075\n",
      "negativeScore:  0\n",
      "CONTRA\n",
      "Sentence:  6yearold cries when told mtm productions kitten dead by now\n",
      "positiveScore:  0\n",
      "negativeScore:  -6.025\n",
      "CONTRA\n",
      "Sentence:  exboyfriend just thought hed check in and throw entire day off\n",
      "positiveScore:  0.19\n",
      "negativeScore:  -0.6\n",
      "CONTRA\n",
      "Sentence:  doctors restore ken burns fullcolor vision after removing massive tumor from filmmakers visual cortex\n",
      "positiveScore:  2.5125\n",
      "negativeScore:  -7.2\n",
      "CONTRA\n",
      "Sentence:  gravity  12 years a slave tie at 2014 pga awards\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m                 df[\u001b[39m'\u001b[39m\u001b[39mCONTRA\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 47\u001b[0m contradictionFeature()\n\u001b[0;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msuccess\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[39m# for sentence in sentences:\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m#     ## implementing 4.4.3\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m#         df['neg_high'] = 0\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39m# df\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 34\u001b[0m, in \u001b[0;36mcontradictionFeature\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m headline \u001b[39m=\u001b[39m remove_symbols(headline)\n\u001b[0;32m     33\u001b[0m sentences \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39msent_tokenize(headline)\n\u001b[1;32m---> 34\u001b[0m scores \u001b[39m=\u001b[39m calculate_scores(headline)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sentences) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCONTRA_PLUS_COHER\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m, in \u001b[0;36mcalculate_scores\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      4\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m nltk\u001b[39m.\u001b[39mword_tokenize(sentence):\n\u001b[1;32m----> 6\u001b[0m     results\u001b[39m.\u001b[39mappend(wScore(word))\n\u001b[0;32m      7\u001b[0m positiveSum \u001b[39m=\u001b[39m positiveScore(results)\n\u001b[0;32m      8\u001b[0m negativeSum \u001b[39m=\u001b[39m negativeScore(results)\n",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m, in \u001b[0;36mwScore\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwScore\u001b[39m(word):\n\u001b[0;32m      2\u001b[0m     senticNet \u001b[39m=\u001b[39m senticNetScore(word)\n\u001b[1;32m----> 3\u001b[0m     sentiStrength \u001b[39m=\u001b[39m sentiStrengthScore(word)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m senticNet \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m sentiStrength \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m         expansion \u001b[39m=\u001b[39m conceptNet(word)\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36msentiStrengthScore\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentiStrengthScore\u001b[39m(word):\n\u001b[1;32m----> 6\u001b[0m     result \u001b[39m=\u001b[39m senti\u001b[39m.\u001b[39;49mgetSentiment(word)\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\sentistrength\\__init__.py:35\u001b[0m, in \u001b[0;36mPySentiStr.getSentiment\u001b[1;34m(self, df_text, score)\u001b[0m\n\u001b[0;32m     33\u001b[0m p \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPopen(shlex\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39mjava -jar \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSentiStrengthLocation \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m stdin sentidata \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSentiStrengthLanguageFolder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m trinary\u001b[39m\u001b[39m\"\u001b[39m),stdin\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,stdout\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,stderr\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE)\n\u001b[0;32m     34\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m(conc_text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m stdout_byte, stderr_text \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mcommunicate(b)\n\u001b[0;32m     36\u001b[0m stdout_text \u001b[39m=\u001b[39m stdout_byte\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m stdout_text \u001b[39m=\u001b[39m stdout_text\u001b[39m.\u001b[39mrstrip()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python\\lib\\subprocess.py:1149\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[0;32m   1150\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python\\lib\\subprocess.py:1523\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1523\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout_thread\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remaining_time(endtime))\n\u001b[0;32m   1524\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1525\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Python\\lib\\threading.py:1089\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1088\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1090\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1091\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Python\\lib\\threading.py:1109\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1109\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1110\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1111\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_scores(sentence):\n",
    "    print(\"Sentence: \",sentence)\n",
    "    score=[]\n",
    "    results = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        results.append(wScore(word))\n",
    "    positiveSum = positiveScore(results)\n",
    "    negativeSum = negativeScore(results)\n",
    "    score.append(positiveSum)\n",
    "    score.append(negativeSum)\n",
    "    print(\"positiveScore: \",positiveSum)\n",
    "    print(\"negativeScore: \",negativeSum)\n",
    "    return score\n",
    "\n",
    "def isContradiction(scores):\n",
    "    if scores[0]!=0 and scores[1]!=0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def checkCoherence(sentence):\n",
    "    tokens = nltk.sent_tokenize(sentence)\n",
    "    if len(tokens) > 1:\n",
    "        if hasAntecedents(sentence):\n",
    "            return True\n",
    "        w1 = extractSubject(tokens[0])\n",
    "        w2 = extractSubject(tokens[1])\n",
    "        if identicalPronouns(w1,w2) or identicalSubjects(w1,w2) or definiteNounPhraseFeature(tokens[1],w2) or demonstrativeNounPhraseFeature(tokens[1],w2) or properNameFeature(w1,w2):\n",
    "            return True   \n",
    "    return False\n",
    "\n",
    "def assignSentimentFeature(headline,scores):\n",
    "    positiveScore = scores[0]\n",
    "    negativeScore = scores[1]\n",
    "    if positiveScore <= -1:\n",
    "        df.loc[df[\"headline\"] == headline, \"pos_low\"] = 1\n",
    "    elif positiveScore >= 0 and positiveScore <= 1:\n",
    "        df.loc[df[\"headline\"] == headline, \"pos_med\"] = 1\n",
    "    elif positiveScore >= 2:\n",
    "        df.loc[df[\"headline\"] == headline, \"pos_high\"] = 1\n",
    "    if negativeScore >= 1:\n",
    "        df.loc[df[\"headline\"] == headline, \"neg_low\"] = 1\n",
    "    elif negativeScore >= 0 and negativeScore <= 1:\n",
    "        df.loc[df[\"headline\"] == headline, \"neg_med\"] = 1\n",
    "    elif negativeScore <= -2:\n",
    "        df.loc[df[\"headline\"] == headline, \"neg_high\"] = 1\n",
    "def contradictionFeature():\n",
    "    for headline in df[\"headline\"]:\n",
    "        headline = remove_symbols(headline)\n",
    "        sentences = nltk.sent_tokenize(headline)\n",
    "        scores = calculate_scores(headline)\n",
    "        assignSentimentFeature(headline,scores)\n",
    "        if len(sentences) > 1:\n",
    "            print(\"CONTRA_PLUS_COHER\")\n",
    "            if isContradiction(scores) and checkCoherence(headline):\n",
    "                df.loc[df[\"headline\"] == headline, \"CONTRA_PLUS_COHER\"] = 1\n",
    "            else:\n",
    "                df.loc[df[\"headline\"] == headline, \"CONTRA_PLUS_COHER\"] = 0\n",
    "        else:\n",
    "            print(\"CONTRA\")\n",
    "            if isContradiction(scores):\n",
    "                df.loc[df[\"headline\"] == headline, \"CONTRA\"] = 1\n",
    "            else:\n",
    "                df.loc[df[\"headline\"] == headline, \"CONTRA\"] = 0\n",
    "contradictionFeature()\n",
    "print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
