{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install stanfordnlp\n",
    "%pip install senticnet\n",
    "%pip install sentistrength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import requests\n",
    "from senticnet.senticnet import SenticNet\n",
    "from sentistrength import PySentiStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the zip file from the link https://drive.google.com/file/d/1yvCpB2URy0iFjQPn3RmidNOryTlo6vHG/view?usp=share_link\n",
    "# extract the zip file and place the folder in the same directory as this file then cd into the folder\n",
    "# run the following command in the terminal to start the server\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port {8000 or any port} -timeout 30000\n",
    "# can speed it up by replace 4g with 8g (it represents the ram being used in gigs)\n",
    "nlp = StanfordCoreNLP(\"http://localhost\", port=8000, timeout=30000)\n",
    "def lemmatize(text):\n",
    "    # perform lemmatization\n",
    "    lemmas = []\n",
    "    output = nlp.annotate(text, properties={'annotators': 'tokenize,lemma', 'outputFormat': 'json'})\n",
    "    output_dict = json.loads(output)\n",
    "    tokens = output_dict['sentences'][0]['tokens']\n",
    "    for token in tokens:\n",
    "        lemmas.append(token['lemma'])\n",
    "   \n",
    "    return lemmas  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the given JSON file into actual JSON format for easier readbility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFile = open(\"Sarcasm_Headlines.json\", \"w\")\n",
    "writeFile.write(\"{ \\\"headlines\\\": [\")\n",
    "with open(\"Sarcasm_Headlines_Dataset.json\") as readFile:\n",
    "  for item in readFile:\n",
    "    writeFile.write(item + \",\")\n",
    "# removed the final comma manually\n",
    "writeFile.write(\"]}\")\n",
    "readFile.close()\n",
    "writeFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Stage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset and removing all article links as our goal is to analyze the headlines for sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = json.load(open(\"Sarcasm_Headlines.json\"))\n",
    "df = pd.DataFrame(dataset[\"headlines\"])\n",
    "df.drop([\"article_link\"], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizeDataset():\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['headline']\n",
    "        row['headline'] = lemmatize(sentence)\n",
    "\n",
    "lemmatizeDataset()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writing to a csv file to avoid having to perform pre-processing again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lemmatized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 => Concept Level and Common Sense Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the API endpoint and parameters\n",
    "endpoint = 'http://api.conceptnet.io/c/en/'\n",
    "params = {\n",
    "    'filter': 'core',\n",
    "    'limit': 1000\n",
    "}\n",
    "def conceptNet(sentence):\n",
    "    # send a GET request to the API endpoint\n",
    "    response = requests.get(endpoint + sentence, params=params)\n",
    "\n",
    "    # parse the JSON response\n",
    "    data = json.loads(response.text)\n",
    "    edges = data['edges']\n",
    "    edges.sort(key=lambda x: x['weight'], reverse=True)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 => Sentiment Score\n",
    "### SentiStrength\n",
    "SentiStrength is a sentiment lexicon that uses linguistic information and rules to detect<br>\n",
    "sentiment strength in English text. SentiStrength provides positive and negative sentiment<br>\n",
    "scores for each word. Both scores are integers from 1 to 5, where 1 signifies weak sentiment<br>\n",
    "and 5 signifies strong sentiment.\n",
    "<br>\n",
    "polarity = positiveSentiment - negativeSentiment\n",
    "\n",
    "### SenticNet\n",
    "SenticNet is a resource for opinion mining that aims to create a collection of commonly<br> \n",
    "used common-sense concepts  with positive and negative sentiment scores. The sentiment <br>\n",
    "score for each word is scaled from -1 to 1, where -1 signifies strongly negative sentiment,<br>\n",
    "0 signifies neutral sentiment and 1 signifies strong positive sentiment.\n",
    "<br> sentiment = score * 5 (in-order to keep it with sentiStrength)\n",
    "\n",
    "### Rules of w_score (sentiment score) selection:\n",
    "- if word belongs to SentiStrength || SenticNet => pick the score whichever exists\n",
    "- if word belongs to SentiStrength && SenticNet => avg score of the lexicons\n",
    "- else get the concepts from concept net to expand the meaning => select top 5 ranked and calculate the avg sentiment score\n",
    "\n",
    "### Final Calculation\n",
    "sum_pos_score = sum of all positive sentiment scores<br>\n",
    "sum_neg_score = sum of all negative sentiment scores<br>\n",
    "if sum_pos_score && sum_neg_score > 0, there is a contradiction in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 1.9700000000000002\n",
      "Negative Score: -1.6\n",
      "Contrast Score: 0.3700000000000001\n"
     ]
    }
   ],
   "source": [
    "sn = SenticNet()\n",
    "senti = PySentiStr()\n",
    "senti.setSentiStrengthPath('D:/Sarcasm_Detection-Feature_Selection/SentiStrength.jar')\n",
    "senti.setSentiStrengthLanguageFolderPath('D:/Sarcasm_Detection-Feature_Selection/SentStrength_Data/')\n",
    "def senticNetScore(word):\n",
    "    try:\n",
    "        polarityValue = sn.polarity_value(word)\n",
    "        return float(polarityValue) * 5\n",
    "    except KeyError:\n",
    "        return None\n",
    "def sentiStrengthScore(word):\n",
    "    result = senti.getSentiment(word)\n",
    "    return result\n",
    "def wScore(word):\n",
    "    senticNet = senticNetScore(word)\n",
    "    sentiStrength = sentiStrengthScore(word)[0]\n",
    "    if senticNet == None and sentiStrength == None:\n",
    "        expansion = conceptNet(word)\n",
    "        if len(expansion) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            score = 0\n",
    "            expansion = expansion[:5]\n",
    "            for edge in expansion:\n",
    "                score += wScore(edge['end']['label'])\n",
    "            return score / 5\n",
    "    elif senticNet == None:\n",
    "        return sentiStrength\n",
    "    elif sentiStrength == None:\n",
    "        return senticNet\n",
    "    else:\n",
    "        return (senticNet + sentiStrength) / 2\n",
    "def positiveScore(results):\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        if result > 0:\n",
    "            score += result\n",
    "    return score\n",
    "def negativeScore(results):\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        if result < 0:\n",
    "            score += result\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
